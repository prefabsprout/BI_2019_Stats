---
title: "BI-2019 Statistics Project №2"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_section: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)

if(!require(corrplot)) install.packages("corrplot",repos = "http://cran.us.r-project.org", dependencies = T)
if(!require(car)) install.packages("car",repos = "http://cran.us.r-project.org", dependencies = T)
if(!require(MASS)) install.packages("MASS",repos = "http://cran.us.r-project.org", dependencies = T)
if(!require(kableExtra)) install.packages("kableExtra",repos = "http://cran.us.r-project.org", dependencies = T)
if(!require(xtable)) install.packages("xtable",repos = "http://cran.us.r-project.org", dependencies = T)
if(!require(purrr)) install.packages("purrr",repos = "http://cran.us.r-project.org", dependencies = T)
if(!require(gridExtra)) install.packages("gridExtra",repos = "http://cran.us.r-project.org", dependencies = T)
if(!require(knitr)) install.packages("knitr",repos = "http://cran.us.r-project.org", dependencies = T)

theme_set(theme_bw())
```

# Полная линейная модель (Обязательная часть)

## Построение модели

Для начала, подгрузим данные и взглянем на них. Также посмотрим и на спецификацию датасета. Увидим, что переменные rad и chas являются факторными переменными. Учтём это.

```{r}
summary(Boston)
```


Стандартизируем наши переменные и представим rad и chas в факторном виде.

```{r}
boston_standart <- as.data.frame(sapply(Boston, scale))
boston_standart$chas <- as.factor(Boston$chas)
boston_standart$rad <- as.factor(Boston$rad)
```


Посмотрим на коллинеарности:

```{r}
mat <- cor(boston_standart[ , purrr::map_lgl(boston_standart, is.numeric)])
corrplot(mat)
```

Построим нашу полную линейную модель без учёта наличия коллинеарностей и взглянем на её summary.

```{r}
full_model <- lm(medv ~ ., boston_standart)
summary(full_model)
```

Получили неплохой, но отнюдь не идеальный коэффициент детерминации. Вернёмся к улучшению результатов во второй части работы. А сейчас...

## Диагностика модели

### Проверка графиков остатков

```{r}
mod_diag <- fortify(full_model)
gg_resid <- ggplot(data = mod_diag, aes(x = .fitted, y = .stdresid)) + 
  geom_point() + 
  geom_hline(yintercept = 0) +
  geom_smooth(method = "lm") +
  geom_hline(yintercept = 2, color = "red") +
  geom_hline(yintercept = -2, color = "red")

gg_resid
```

Сделаем определенные выводы:

* Модель обладает определенной линейностью взаимосвязи
* Относительно много наблюдений находятся за пределеами зоны +- 2 стандартных отклонения
* Гетероскедастичность отсутствует

Неплохо, но довольно сильные отклонения за пределы доверительного интервала смущают.

### Проверка на выбросы

Для начала, подберём маржу, выход за границу которой будем считать выбросом.
Ссылка, откуда взята формула - (https://www.rstatisticsblog.com/data-science-in-action/identifying-outliers/ (соответствующий раздел про расстояние Кука))

```{r}
metric <- 4/nrow(boston_standart)
```


```{r}
ggplot(mod_diag, aes(x = 1:nrow(mod_diag), y = .cooksd)) + 
  geom_bar(stat = "identity") + 
  geom_hline(yintercept = metric, color = "red")
```
 
Обнаружим немалое количество выбросов.

### Проверка на наличие независимых наблюдений

```{r}
durbinWatsonTest(full_model)
```

Значение статистики автокорреляции значительно меньше двух. P value так и вовсе стремится к нулю. Таким образом, автокорреляция определенно присутствует.

### Проверка на нормальность распределения

Построим квантиль-квантиль график:

```{r}
qqPlot(mod_diag$.fitted)
```

Делаем вывод об ассиметричности распределения - левый хвост распределения выходит более длинный. Распределение нельзя назвать нормальным.


## Предсказания модели

Создадим тествовый датасет с предсказаниями:

```{r}
test_data_fm <- data.frame(
  lstat = seq(min(Boston$lstat), max(Boston$lstat), length.out = 506),
  crim = mean(Boston$crim),
  zn = mean(Boston$zn),
  indus = mean(Boston$indus),
  chas = as.factor(Boston$chas),
  hb = mean(rock$hb),
  nox = mean(Boston$nox),
  rm = mean(Boston$rm),
  age = mean(Boston$age),
  dis = mean(Boston$dis),
  rad = as.factor(Boston$rad),
  tax = mean(Boston$tax),
  ptratio = mean(Boston$ptratio),
  black = mean(Boston$black)
  )
```

Собственно, осуществим предсказания:

```{r}
predictions <- predict(full_model, newdata = test_data_fm,  interval = 'confidence')
test_data_fm <- cbind(test_data_fm, predictions)
```

И построим график с предсказаниями:

```{r}
ggplot(test_data_fm, aes(x = lstat, y = fit)) +
  geom_ribbon(alpha = 0.2, aes(ymin = lwr, ymax = upr)) +
  geom_line() 
```


Та-да-а! 
Казалось бы, цель достигнута. Но...

# Улучшение модели (Дополнительная часть)

## Подбор оптимальной модели

### Подбор модели

Итак. Подберём идеально подходящую модель. Использовать для этого будем частный F тест из функции summary. Воспользуемся алгоритмом backward-selection (из полной модели последовательно удаляем предикторы). Выбрасывать будем незначимые предикторы. Кроме того, отбросим переменную chas (т.к. согласно спецификации, это факторная переменная, которая ещё и dummy переменная ("болванчиковая" переменная)) - будем считать, что её влияние модель незначимо:

```{r}
summary(full_model)
mod_1 <- update(full_model, .~. - chas)

summary(mod_1)
mod_2 <- update(mod_1, .~. - indus)

summary(mod_2)
mod_3 <- update(mod_2, .~. - age)

summary(mod_3)
```


### Подбор модели без коллинеарности

Для этого используем критерий VIF (Variance inflation factor). Если VIF предиктора модели будет выше 2, то нам следует удалить этот предиктор. Если таких предикторов несколько, то нам следует аккуратно пошагово удалить все такие предикторы, пока VIF не будут менее двух.

Итак, запустим VIF:
```{r}
vif(mod_3)
```

Похоже, что у VIF проблемы с расчётом для факторной переменной c большим количеством градаций. Уберём переменную rad:
```{r}
mod_4 <- update(mod_3, .~. - rad)
vif(mod_4)
```

Отлично. Получили несколько переменных с VIF > 2. Будем удалять VIF в порядке от максимального 
до минимального. Начнём с nox:

```{r}
mod_5 <- update(mod_4, .~. - nox)
vif(mod_5)
```

```{r}
mod_6 <- update(mod_5, .~. - dis)
vif(mod_6)
```

```{r}
mod_7 <- update(mod_6, .~. - lstat)
vif(mod_7)
```

## Диагностика модели

### Коррекция модели 

Создадим датасет с данными для анализа остатков и построим график остатков (не будем учитывать наши факторы):

```{r}
mod_diag_adj <- data.frame(fortify(mod_7), boston_standart$lstat, boston_standart$dis,
                           boston_standart$nox, boston_standart$age,
                           boston_standart$indus)


gg_resid <- ggplot(data = mod_diag_adj, aes(x = .fitted, y = .stdresid)) + 
  geom_point() + 
  geom_hline(yintercept = 0) +
  geom_smooth(method = 'lm') +
  geom_hline(yintercept = 2, color = "red") +
  geom_hline(yintercept = -2, color = "red")
gg_resid

```

Сделаем определенные выводы:

* Модель обладает определенной линейностью взаимосвязи
* Относительно много (но на вид меньше, чем в предыдущей модели) наблюдений находятся за пределеами зоны +- 2 стандартных отклонения
* Гетероскедастичность отсутствует

Кроме того, построим такие же графики для удалённых переменных:

```{r}
res_1 <- gg_resid + aes(x = boston_standart.indus)
res_2 <- gg_resid + aes(x = boston_standart.age)
res_3 <- gg_resid + aes(x = boston_standart.nox)
res_4 <- gg_resid + aes(x = boston_standart.dis)
res_5 <- gg_resid + aes(x = boston_standart.lstat)

grid.arrange(res_1, res_2, res_3, res_4, res_5, nrow = 2)
```

Увидим неучтённые зависимости (dis и lstat) и вернём их в модель. Повторно проведём F тесты. Увидим, что от удаления age немного ухудшается исправленный R2 и вернём его назад:

```{r}
mod_8 <- update(mod_7, .~. + lstat + dis)
summary(mod_8)
  
mod_9 <- update(mod_8, .~. - age)
summary(mod_9)

mod_10 <- update(mod_9, .~. + age)
summary(mod_10)

```

Немного погрустим из-за того, что у нас ухудшился R2 (0.7079 у новой модели против 0.7363 у старой). Почему-то.

### Проверка графиков остатков

Повторно построим график остатков:

```{r}
mod_diag_adj <- data.frame(fortify(mod_10), boston_standart$dis,
                           boston_standart$nox, boston_standart$age,
                           boston_standart$indus)


gg_resid <- ggplot(data = mod_diag_adj, aes(x = .fitted, y = .stdresid)) + 
  geom_point() + 
  geom_hline(yintercept = 0) +
  geom_smooth(method = "lm") +
  geom_hline(yintercept = 2, color = "red") +
  geom_hline(yintercept = -2, color = "red")
gg_resid
```

Сделаем такой же вывод как и в прошлый раз:

* Модель обладает определенной линейностью взаимосвязи
* Относительно много (но на вид меньше, чем в предыдущей модели) наблюдений находятся за пределеами зоны +- 2 стандартных отклонения
* Гетероскедастичность отсутствует

### Проверка на выбросы

```{r}
metric <- 4/nrow(boston_standart)
```


```{r}
ggplot(mod_diag, aes(x = 1:nrow(mod_diag_adj), y = .cooksd)) + 
  geom_bar(stat = "identity") + 
  geom_hline(yintercept = metric, color = "red")
```
 
Обнаружим такое же немалое количество выбросов.

### Проверка на наличие независимых наблюдений

```{r}
durbinWatsonTest(mod_10)
```

Значение статистики автокорреляции значительно меньше двух, но оно хотя бы лучше, чем было в полной модели.

### Проверка на нормальность распределения

Построим квантиль-квантиль график:

```{r}
qqPlot(mod_diag_adj$.fitted)
```

Ой. По неким причинам распределение стало ещё более асимметричным, чем было до этого.


## Предсказания модели

Создадим тествовый датасет с предсказаниями:

```{r}
summary(mod_10)
```


```{r}
test_data_10 <- data.frame(
  lstat = seq(min(Boston$lstat), max(Boston$lstat), length.out = 506),
  crim = mean(Boston$crim),
  zn = mean(Boston$zn),
  rm = mean(Boston$rm),
  tax = mean(Boston$tax),
  ptratio = mean(Boston$ptratio),
  black = mean(Boston$black),
  age = mean(Boston$age),
  dis = mean(Boston$dis)
  )
```

Собственно, осуществим предсказания:

```{r}
predictions <- predict(mod_10, newdata = test_data_10,  interval = 'confidence')
test_data_10 <- cbind(test_data_10, predictions)
```

И построим график с предсказаниями:

```{r}
ggplot(test_data_10, aes(x = lstat, y = fit)) +
  geom_ribbon(alpha = 0.2, aes(ymin = lwr, ymax = upr)) +
  geom_line() 
```


## Интерпретация модели

### Статистика по модели

Ещё раз выведем summary от итоговой модели:

```{r}
summary(mod_10)
```

Напишем формулу полученной линейной регрессии:

$$medv = {-1.540*10^{-16}*crim -5.621*10^{-2}*zn + 1.136*10^{-1}*rm + 3.371*10^{-1}*tax - 6.697*10^{-2}*tax - 1.689*10^{-1}*ptratio + 9.784*10^{-2}*black -4.256*10^{-1}*lstat - 2.704*10^{-1}*dis -5.248*10^{-2}*age}$$

Построим красивую табличку для статьи:

```{r}
summary(mod_10) %>% xtable() %>% kable %>% kable_styling()
```

Исправленный R2 = 0.7079 

Матрица корреляций для изначальных данных:

```{r}
mat <- cor(boston_standart[ , purrr::map_lgl(boston_standart, is.numeric)])
corrplot(mat)
```

### Выводы по качеству и дискуссия

Странно, но вопреки мероприятиям по исправлению качества, оно ухудшилось. Исправленный R2 = 0.7079 у новой модели против R2 = 0.7363 у старой. Возможно, это связано с попытками избавиться от мультиколлинеарности с помощью VIF. Вероятно, лучшей альтернативой было бы использование PCA.

Кроме того, вероятно, что само линейное моделирование для данного конкретного датасета - это не самое лучшее решение. Возможно, использование LASSO (least absolute shrinkage and selection operator) было бы более хорошим решением.